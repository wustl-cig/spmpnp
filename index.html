<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Plug-and-Play Methods for Integrating Physical and Learned Models in Computational Imaging">
    <meta name="author" content="Ulugbek S. Kamilov,
    Charles A. Bouman,
    Gregery T. Buzzard,
    Brendt Wohlberg">

    <title>Plug-and-Play Methods for Integrating Physical and Learned Models in Computational Imaging</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="src/css/style.css">

</head>

<body>

<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Plug-and-Play Methods for Integrating Physical and Learned Models in Computational Imaging</h2>
    <h3>IEEE Signal Processing Magazine</h3>
            <p class="abstract"><b>Tutorial on Plug-and-Play </b></p>
    <hr>
    <p class="authors">
        <a href="https://wjgancn.github.io"> Weijie Gan<sup>1</sup></a>,
        <a href="https://sunyumark.github.io"> Yu Sun<sup>1</sup></a>,
        <a href="https://scholar.google.com/citations?user=PU44ObcAAAAJ&hl=en"> Cihat Eldeniz<sup>2</sup></a>,
        <a href="https://jiamingliu-jeremy.github.io"> Jiaming Liu<sup>3</sup></a>,
        <a href="https://profiles.wustl.edu/en/persons/hongyu-an"> Hongyu An<sup>2,3,4,5</sup></a> 
        <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html"> Ulugbek S. Kamilov<sup>1,3</sup></a> </br>
    </p>
    <p>
        <a><sup>1</sup>Department of Computer Science & Engineering, Washington University in St.Louis, St. Louis, MO, USA</a></br>
        <a><sup>2</sup>Mallinckrodt Institute of Radiology,Washington University in St. Louis, St.Louis, MO, USA</a></br>
        <a><sup>3</sup>Department of Electrical & SystemsEngineering, Washington University in St.Louis, St. Louis, MO, USA</a></br>
        <a><sup>4</sup>Department of Biomedical Engineering,Washington University in St. Louis, St.Louis, MO, USA</a></br>
        <a><sup>5</sup>Department of Neurology, WashingtonUniversity in St. Louis, St. Louis, MO, USA</a></br>
    </p>

    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://ieeexplore.ieee.org/document/9743932">Paper</a>
        <a class="btn btn-primary" href="https://arxiv.org/abs/2107.05533">Preprint</a>
        <a class="btn btn-primary" href="https://github.com/wustl-cig/DeCoLearn">Code</a>
    </div>

    <p>We are grateful to <b>Vivian Chen</b> for her contributions to this project website.</p>
</div>

<div class="container">
    <div class="section">

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/GIF.gif" style="width:85%" alt="Banner">
                <p>An illustration of DeCoLearn training procedure.</p>
            </div>
        </div>

        <br>
        <h2>Abstract</h2>
        <hr>
        <p>
            Deep neural networks for medical image reconstruction are traditionally trained using high-quality ground-truth images as training targets. Recent work on Noise2Noise (N2N) has shown the potential of using multiple noisy measurements of the same object as an alternative to having a ground-truth. However, existing N2N-based methods are not suitable for learning from the measurements of an object undergoing nonrigid deformation. This paper addresses this issue by proposing the <b>deformation-compensated learning (DeCoLearn)</b> method for training deep reconstruction networks by compensating for object deformations. A key component of DeCoLearn is a deep registration module, which is jointly trained with the deep reconstruction network without any ground-truth supervision. We validate DeCoLearn on both simulated and experimentally collected magnetic resonance imaging (MRI) data and show that it significantly improves imaging quality.
        </p>
    </div>

    <div class="section">
        <h2>Model</h2>
        <hr>
        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img style="width:100%" src="img/model.png" >
            </div>
        </div>
    </div>
    
    <div class="section">
        <h2>Validation on Experimentally-Collected 4D MRI Data</h2>
        <hr>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/video_slice.gif" style="width:70%" alt="Banner">
                <p>A video of DeCoLearn reconstructed images across <i>different slice</i>. <b>LEFT</b>: inverse multi-coil non-uniform fast Fourier transform (MCNUFFT). <b>RIGHT</b>: DeCoLearn.</p>
            </div>
        </div>
        
        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/video_phase.gif" style="width:70%" alt="Banner">
                <p>A video of DeCoLearn reconstructed images across <i>different respiratory phase</i>. <b>LEFT</b>: inverse multi-coil non-uniform fast Fourier transform (MCNUFFT). <b>RIGHT</b>: DeCoLearn.</p>
            </div>
        </div>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/result_phase.png" style="width:95%" alt="Banner">
                <p>An illustration of DeCoLearn reconstructed images across <i>different respiratory phase</i>.</p>
            </div>
        </div>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/result_slice.png" style="width:85%" alt="Banner">
                <p>An illustration of DeCoLearn reconstructed images compared against several baseline methods.</p>
            </div>
        </div>
        
    </div>

    <div class="section">
        <h2>Validation on Simulated Data</h2>
        <div class="text-center">
        <p>Check our <a href="https://github.com/wustl-cig/DeCoLearn"> GitHub </a> to generate the following results by yourself.</p>
        </div>
        <hr>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/video_simulated_data.gif" style="width:100%" alt="Banner">
            </div>
        </div>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/result_simulated_data.png" style="width:100%" alt="Banner">
            </div>
        </div>
    </div>
    
    <div class="section">
        <h2>Paper</h2>
        <hr>
        <div>
            <div class="list-group">
                <a href="https://arxiv.org/abs/2107.05533"
                   class="list-group-item">
                    <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">
                </a>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
            @article{gan2021deformation,
                title={Deformation-Compensated Learning for 
                    Image Reconstruction without Ground Truth},
                author={Gan, Weijie and Sun, Yu and Eldeniz, Cihat 
                    and Liu, Jiaming and An, Hongyu and Kamilov, Ulugbek S},
                journal={IEEE Transactions on Medical Imaging},
                year={2022}
              }
        </div>
    </div>

    <hr>

   <footer>
       <p>Acknoledgement: Web template from <a href="https://www.vincentsitzmann.com/siren/">SIREN</a> and <a href="https://wustl-cig.github.io/curewww">CURE</a></p>
   </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
