<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Plug-and-Play Methods for Integrating Physical and Learned Models in Computational Imaging">
    <meta name="author" content="Ulugbek S. Kamilov,
    Charles A. Bouman,
    Gregery T. Buzzard,
    Brendt Wohlberg">

    <title>Plug-and-Play Methods for Integrating Physical and Learned Models in Computational Imaging</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="src/css/style.css">

</head>

<body>

<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Plug-and-Play Methods for Integrating Physical and Learned Models in Computational Imaging</h2>
    <p class="abstract"><b>IEEE Signal Processing Magazine tutorial on Plug-and-Play Methods</b></p>
    <hr>
    <p class="authors">
        <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html"> Ulugbek S. Kamilov<sup>1</sup></a>,
        <a href="https://engineering.purdue.edu/~bouman">Charles A. Bouman<sup>2</sup></a>,
        <a href="https://www.math.purdue.edu/~buzzard">Gregery T. Buzzard<sup>3</sup></a>,
        <a href="http://brendt.wohlberg.net">Brendt Wohlberg<sup>4</sup></a></br>
    </p>
    <p>
        <a><sup>1</sup>Computational Imaging Group (CIG), Washington University in St.Louis, St. Louis, MO, USA</a></br>
        <a><sup>2</sup>Electrical & Computer Engineering, Purdue University, West Lafayette, IN, USA</a></br>
        <a><sup>3</sup>Department of Mathematics, Purdue University, West Lafayette, IN, USA</a></br>
        <a><sup>4</sup> Theoretical Division at Los Alamos National Laboratory, Los Alamos, NM, USA</a></br>
    </p>

    <div class="btn-group" role="group" aria-label="Top menu">
        <!--<a class="btn btn-primary" href="https://ieeexplore.ieee.org/document/9743932">Paper</a>-->
        <a class="btn btn-primary" href="https://arxiv.org/abs/2203.17061">Preprint</a>
        <a class="btn btn-primary" href="https://github.com/lanl/scico-data/blob/main/notebooks/superres_ppp_dncnn_admm.ipynb">Code</a>
    </div>
</div>

<div class="container">
    <div class="section">

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/fig2.jpg" style="width:85%" alt="Banner">
                <p><b>Figure 1:</b> Image priors for PnP can be obtained by training CNNs to remove AWGN from a set of images.</p>
            </div>
        </div>

        <br>
        <h2>Abstract</h2>
        <hr>
        <p>
            <b>Plug-and-Play Priors (PnP)</b> is one of the most widely-used frameworks for solving computational imaging problems through the integration of physical models and learned models. PnP leverages high-fidelity physical sensor models and powerful machine learning methods for prior modeling of data to provide state-of-the-art reconstruction algorithms. PnP algorithms alternate between minimizing a data-fidelity term to promote data consistency and imposing a learned regularizer in the form of an image denoiser. Recent highly-successful applications of PnP algorithms include bio-microscopy, computerized tomography, magnetic resonance imaging, and joint ptycho-tomography. This article presents a unified and principled review of PnP by tracing its roots, describing its major variations, summarizing main results, and discussing applications in computational imaging. We also point the way towards further developments by discussing recent results on equilibrium equations that formulate the problem associated with PnP algorithms.
        </p>
    </div>

    <div class="section">
        <h2>Deep Model-Based Architectures</h2>
        <hr>
        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img style="width:90%" src="img/fig9.jpg" >
                <p><b>Figure 2:</b> The PnP framework is related to two other popular computational-imaging paradigms, deep unfolding (DU) and deep equilibrium models (DEQ). A PnP algorithm, such as PnP-ISTA or RED-SD, can be turned into a DU architecture by truncating the algorithm to a fixed number of iterations and training the weights of the CNN prior end-to-end. Similarly, a DEQ architecture can be obtained by running the PnP algorithm until convergence and using the implicit differentiation at the fixed point to train the weights. The CNN operator in DU/DEQ is not necessarily an AWGN denoiser, instead it is an artifact-removal (AR) operator trained to remove artifacts specific to the PnP iterations</p>
            </div>
        </div>
    </div>
    
    <div class="section">
        <h2>Applications of PnP</h2>
        <hr>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/fig3.jpg" style="width:90%" alt="Banner">
                <p><b>Figure 3:</b> A single pre-trained CNN denoiser in PnP can address different super-resolution factors.</p>
            </div>
        </div>
        
        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/fig5.jpg" style="width:90%" alt="Banner">
                <p><b>Figure 4:</b> PnP algorithms explicitly separate the application of the forward model from that of the learned prior, enabling the adaptation of trained CNNs to new sensor configurations.  This is illustrated on experimentally collected 3D MRI data corresponding to 800 radial spokes (scans of about 2 minute). MCNUFFT refers to a simple inversion of the measurement operator without any regularization. DeCoLearn is a CNN that was trained under a mismatched sensor configuration corresponding to 1600 lines (scans of about 4 minutes). A variant of PnP called RARE is used to adapt DeCoLearn to the desired 800 line data. The results of the DeCoLearn reconstruction using all the available 2000 lines is shown as Reference. The numbers on the top-right corner correspond to the relative PSNR/SSIM values with respect to Reference. Note the ability of RARE to successfully adapt DeCoLearn to 800-line data.</p>
            </div>
        </div>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/fig6.jpg" style="width:90%" alt="Banner">
                <p><b>Figure 5:</b> Visual evaluation of color image recovery in compressive sensing from random projections with 20% subsampling. The results of total variation (TV) and a well-known deep unfolding (DU) architecture ISTA-Net+ are provided for reference. The methods PnP (denoising) and RED (denoising) use a pre-trained AWGN denoiser as an image prior. The method PnP (AR) uses a problem-dependent artifact-removal (AR) operator pre-trained using DU. Note that the choice of denoiser affects the reconstruction significantly (PSNR shown in white).</p>
            </div>
        </div>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/fig8.jpg" style="width:90%" alt="Banner">
                <p><b>Figure 6:</b> Online PnP algorithms, such as SIMBA, can reduce the computational and memory complexity of PnP. Here, we show the reconstruction of a 3D algae sample from 89 experimentally collected intensity diffraction tomography (IDT) measurements (see four images on the left). SIMBA, which uses minibatches of size p = 10, is compared against RED-SD, which uses all b = 89 measurements at each iteration. Both algorithms use exactly the same measurement model and the same DnCNN AWGN denoiser. Note how the results of SIMBA are indistinguishable from RED-SD even though the per-iteration complexity of SIMBA is only a fraction of that of RED-SD.</p>
            </div>
        </div>
        
    </div>
    
    <div class="section">
        <h2>Paper</h2>
        <hr>
        <div>
            <div class="list-group">
                <a href="https://arxiv.org/abs/2203.17061"
                   class="list-group-item">
                    <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">
                </a>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
            @article{kamilov2022pnp,
                title={Plug-and-Play Methods for Integrating Physical 
                and Learned Models in Computational Imaging},
                author={Kamilov, Ulugbek S and Bouman, Charles B and 
                    Buzzard, Gregery T and Wohlberg, Brendt},
                journal={IEEE Signal Process. Mag.},
                year={2022}
              }
        </div>
    </div>

    <hr>

   <footer>
       <p>Acknoledgement: Web template of <a href="https://www.vincentsitzmann.com/siren/">SIREN</a></p>
   </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
