<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Plug-and-Play Methods for Integrating Physical and Learned Models in Computational Imaging">
    <meta name="author" content="Ulugbek S. Kamilov,
    Charles A. Bouman,
    Gregery T. Buzzard,
    Brendt Wohlberg">

    <title>Plug-and-Play Methods for Integrating Physical and Learned Models in Computational Imaging</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="src/css/style.css">

</head>

<body>

<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Plug-and-Play Methods for Integrating Physical and Learned Models in Computational Imaging</h2>
    <p class="abstract"><b>IEEE Signal Processing Magazine Tutorial on Plug-and-Play Methods</b></p>
    <hr>
    <p class="authors">
        <a href="https://engineering.wustl.edu/faculty/Ulugbek-Kamilov.html"> Ulugbek S. Kamilov<sup>1,2</sup></a>,
        <a href="https://engineering.purdue.edu/~bouman">Charles A. Bouman<sup>3</sup></a>,
        <a href="https://www.math.purdue.edu/~buzzard">Gregery T. Buzzard<sup>4</sup></a>,
        <a href="http://brendt.wohlberg.net">Brendt Wohlberg<sup>5</sup></a></br>
    </p>
    <p>
        <a><sup>1</sup>Department of Computer Science & Engineering, Washington University in St.Louis, St. Louis, MO, USA</a></br>
        <a><sup>2</sup>Department of Electrical & Systems Engineering, Washington University in St.Louis, St. Louis, MO, USA</a></br>
        <a><sup>3</sup>Electrical & Computer Engineering, Purdue University, West Lafayette, IN, USA</a></br>
        <a><sup>4</sup>Department of Mathematics, Purdue University, West Lafayette, IN, USA</a></br>
        <a><sup>5</sup> Theoretical Division at Los Alamos National Laboratory, Los Alamos, NM, USA</a></br>
    </p>

    <div class="btn-group" role="group" aria-label="Top menu">
        <!--<a class="btn btn-primary" href="https://ieeexplore.ieee.org/document/9743932">Paper</a>-->
        <a class="btn btn-primary" href="https://arxiv.org/abs/2203.17061">Preprint</a>
        <a class="btn btn-primary" href="https://github.com/lanl/scico-data/blob/main/notebooks/superres_ppp_dncnn_admm.ipynb">Code</a>
    </div>
</div>

<div class="container">
    <div class="section">

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/fig2.jpg" style="width:85%" alt="Banner">
                <p> Image priors for PnP can be obtained by training CNNs to remove AWGN from a set of images.</p>
            </div>
        </div>

        <br>
        <h2>Abstract</h2>
        <hr>
        <p>
            <b>Plug-and-Play Priors (PnP)</b> is one of the most widely-used frameworks for solving computational imaging problems through the integration of physical models and learned models. PnP leverages high-fidelity physical sensor models and powerful machine learning methods for prior modeling of data to provide state-of-the-art reconstruction algorithms. PnP algorithms alternate between minimizing a data-fidelity term to promote data consistency and imposing a learned regularizer in the form of an image denoiser. Recent highly-successful applications of PnP algorithms include bio-microscopy, computerized tomography, magnetic resonance imaging, and joint ptycho-tomography. This article presents a unified and principled review of PnP by tracing its roots, describing its major variations, summarizing main results, and discussing applications in computational imaging. We also point the way towards further developments by discussing recent results on equilibrium equations that formulate the problem associated with PnP algorithms.
        </p>
    </div>

    <div class="section">
        <h2>Relationship to Deep Unfolding</h2>
        <hr>
        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img style="width:90%" src="img/fig9.jpg" >
                <p>The PnP framework is related to two other popular computational-imaging paradigms, deep unfolding (DU) and deep equilibrium models (DEQ). A PnP algorithm, such as PnP-ISTA or RED-SD, can be turned into a DU architecture by truncating the algorithm to a fixed number of iterations and training the weights of the CNN prior end-to-end. Similarly, a DEQ architecture can be obtained by running the PnP algorithm until convergence and using the implicit differentiation at the fixed point to train the weights. The CNN operator in DU/DEQ is not necessarily an AWGN denoiser, instead it is an artifact-removal (AR) operator trained to remove artifacts specific to the PnP iterations</p>
            </div>
        </div>
    </div>
    
    <div class="section">
        <h2>Applications of PnP</h2>
        <hr>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/fig3.jpg" style="width:90%" alt="Banner">
                <p> A single pre-trained CNN denoiser in PnP can address different super-resolution factors.</p>
            </div>
        </div>
        
        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/fig5.jpg" style="width:90%" alt="Banner">
                <p>PnP algorithms explicitly separate the application of the forward model from that of the learned prior, enabling the adaptation of trained CNNs to new sensor configurations.  This is illustrated on experimentally collected 3D MRI data corresponding to 800 radial spokes (scans of about 2 minute).</p>
            </div>
        </div>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/result_phase.png" style="width:95%" alt="Banner">
                <p>An illustration of DeCoLearn reconstructed images across <i>different respiratory phase</i>.</p>
            </div>
        </div>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/result_slice.png" style="width:85%" alt="Banner">
                <p>An illustration of DeCoLearn reconstructed images compared against several baseline methods.</p>
            </div>
        </div>
        
    </div>

    <div class="section">
        <h2>Validation on Simulated Data</h2>
        <div class="text-center">
        <p>Check our <a href="https://github.com/wustl-cig/DeCoLearn"> GitHub </a> to generate the following results by yourself.</p>
        </div>
        <hr>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/video_simulated_data.gif" style="width:100%" alt="Banner">
            </div>
        </div>

        <div class="row align-items-center">
			<div class="col justify-content-center text-center">
                <img src="img/result_simulated_data.png" style="width:100%" alt="Banner">
            </div>
        </div>
    </div>
    
    <div class="section">
        <h2>Paper</h2>
        <hr>
        <div>
            <div class="list-group">
                <a href="https://arxiv.org/abs/2107.05533"
                   class="list-group-item">
                    <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">
                </a>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
            @article{gan2021deformation,
                title={Deformation-Compensated Learning for 
                    Image Reconstruction without Ground Truth},
                author={Gan, Weijie and Sun, Yu and Eldeniz, Cihat 
                    and Liu, Jiaming and An, Hongyu and Kamilov, Ulugbek S},
                journal={IEEE Transactions on Medical Imaging},
                year={2022}
              }
        </div>
    </div>

    <hr>

   <footer>
       <p>Acknoledgement: Web template from <a href="https://www.vincentsitzmann.com/siren/">SIREN</a> and <a href="https://wustl-cig.github.io/curewww">CURE</a></p>
   </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
